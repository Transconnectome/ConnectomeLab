{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Parameters:</strong>\n",
    "1. Cross Validation nubmer: 5 (both inner and outer)\n",
    "2. n_estimator: 10, 20, 30, ... , 190, 200\n",
    "3. max_depth: 5 (I tried 5, 10, 15, ... but 5 was the best)\n",
    "4. X <- GPS and age, female, hign.educ....\n",
    "\n",
    "<strong>Result:</strong>\n",
    "- best max depth: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = pd.read_csv('/home/ubuntu/phenotype_and_GPS.csv', header=0)\n",
    "my_data['KEY'] = my_data['KEY'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I placed NAN to mean value... should I replace it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data.fillna(my_data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KEY</th>\n",
       "      <th>AD</th>\n",
       "      <th>DEPRESSION_SUB</th>\n",
       "      <th>IQ</th>\n",
       "      <th>NEUROTICISM</th>\n",
       "      <th>WORRY_SUB</th>\n",
       "      <th>INSOMNIA</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>SNORING</th>\n",
       "      <th>CP</th>\n",
       "      <th>...</th>\n",
       "      <th>income</th>\n",
       "      <th>married</th>\n",
       "      <th>abcd_site</th>\n",
       "      <th>vol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>NIH_totcomp</th>\n",
       "      <th>NIH_flucomp</th>\n",
       "      <th>CBCL_TotProb</th>\n",
       "      <th>CBCL_Internal</th>\n",
       "      <th>CBCL_External</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NDARINV003RTV85</td>\n",
       "      <td>-5.780160</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-2.917600</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>-0.307129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>-2.156561</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.050932</td>\n",
       "      <td>20.480539</td>\n",
       "      <td>0.632147</td>\n",
       "      <td>0.605564</td>\n",
       "      <td>-0.789382</td>\n",
       "      <td>-0.731957</td>\n",
       "      <td>-0.589077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NDARINV007W6H7B</td>\n",
       "      <td>9.133668</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>0.438520</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>-3.683131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>1.293196</td>\n",
       "      <td>18.234286</td>\n",
       "      <td>1.069812</td>\n",
       "      <td>0.887103</td>\n",
       "      <td>0.268149</td>\n",
       "      <td>0.534371</td>\n",
       "      <td>-0.418541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NDARINV00BD7VDC</td>\n",
       "      <td>2.059180</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>-4.261953</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>-0.016278</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>-4.160142</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.129021</td>\n",
       "      <td>16.329800</td>\n",
       "      <td>0.632147</td>\n",
       "      <td>1.544026</td>\n",
       "      <td>-0.065808</td>\n",
       "      <td>-0.008341</td>\n",
       "      <td>-0.248005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NDARINV00J52GPG</td>\n",
       "      <td>8.591499</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>-2.582771</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-0.328521</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>-4.682147</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.522359</td>\n",
       "      <td>17</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>19.061896</td>\n",
       "      <td>0.329044</td>\n",
       "      <td>0.237332</td>\n",
       "      <td>-0.399765</td>\n",
       "      <td>-0.912861</td>\n",
       "      <td>-0.589077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NDARINV00NPMHND</td>\n",
       "      <td>3.104598</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-3.145087</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008245</td>\n",
       "      <td>-4.843486</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.663349</td>\n",
       "      <td>17.663472</td>\n",
       "      <td>-0.680849</td>\n",
       "      <td>-1.365205</td>\n",
       "      <td>1.325680</td>\n",
       "      <td>3.247931</td>\n",
       "      <td>-0.248005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               KEY        AD  DEPRESSION_SUB        IQ  NEUROTICISM  \\\n",
       "0  NDARINV003RTV85 -5.780160        0.002583 -2.917600     0.013433   \n",
       "1  NDARINV007W6H7B  9.133668        0.002060  0.369931     0.000064   \n",
       "2  NDARINV00BD7VDC  2.059180        0.006631 -4.261953     0.012193   \n",
       "3  NDARINV00J52GPG  8.591499        0.004259 -2.582771     0.013623   \n",
       "4  NDARINV00NPMHND  3.104598        0.000878 -3.145087     0.013695   \n",
       "\n",
       "   WORRY_SUB  INSOMNIA      PTSD   SNORING        CP  ...  income   married  \\\n",
       "0  -0.000821 -0.307129  0.000000  0.063292 -2.156561  ...     8.0  1.000000   \n",
       "1  -0.001469  0.438520  0.017525  0.021098 -3.683131  ...    10.0  1.000000   \n",
       "2  -0.016278  0.071778  0.010899  0.037388 -4.160142  ...    10.0  1.000000   \n",
       "3   0.000487 -0.328521  0.019801  0.022991 -4.682147  ...     6.0  1.522359   \n",
       "4  -0.013129  0.014641  0.000000 -0.008245 -4.843486  ...     8.0  1.000000   \n",
       "\n",
       "   abcd_site       vol        BMI  NIH_totcomp  NIH_flucomp  CBCL_TotProb  \\\n",
       "0          6 -1.050932  20.480539     0.632147     0.605564     -0.789382   \n",
       "1         22  1.293196  18.234286     1.069812     0.887103      0.268149   \n",
       "2          7  1.129021  16.329800     0.632147     1.544026     -0.065808   \n",
       "3         17  0.020277  19.061896     0.329044     0.237332     -0.399765   \n",
       "4         17  0.663349  17.663472    -0.680849    -1.365205      1.325680   \n",
       "\n",
       "   CBCL_Internal  CBCL_External  \n",
       "0      -0.731957      -0.589077  \n",
       "1       0.534371      -0.418541  \n",
       "2      -0.008341      -0.248005  \n",
       "3      -0.912861      -0.589077  \n",
       "4       3.247931      -0.248005  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONSTANTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples:  4567\n",
      "fold_size:  914\n"
     ]
    }
   ],
   "source": [
    "k_fold = 5\n",
    "\n",
    "num_samples = len(my_data)\n",
    "each_fold_size = int(num_samples/k_fold) +1\n",
    "\n",
    "print('num_samples: ', num_samples)\n",
    "print('fold_size: ', each_fold_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PARAMETERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD</th>\n",
       "      <th>DEPRESSION_SUB</th>\n",
       "      <th>IQ</th>\n",
       "      <th>NEUROTICISM</th>\n",
       "      <th>WORRY_SUB</th>\n",
       "      <th>INSOMNIA</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>SNORING</th>\n",
       "      <th>CP</th>\n",
       "      <th>excl23andMe</th>\n",
       "      <th>...</th>\n",
       "      <th>HAPPINESS</th>\n",
       "      <th>age</th>\n",
       "      <th>female</th>\n",
       "      <th>race</th>\n",
       "      <th>high.educ</th>\n",
       "      <th>income</th>\n",
       "      <th>married</th>\n",
       "      <th>abcd_site</th>\n",
       "      <th>vol</th>\n",
       "      <th>BMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.780160</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-2.917600</td>\n",
       "      <td>0.013433</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>-0.307129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063292</td>\n",
       "      <td>-2.156561</td>\n",
       "      <td>-0.248034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.050932</td>\n",
       "      <td>20.480539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.133668</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>0.438520</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.021098</td>\n",
       "      <td>-3.683131</td>\n",
       "      <td>-1.858655</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>1.293196</td>\n",
       "      <td>18.234286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.059180</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>-4.261953</td>\n",
       "      <td>0.012193</td>\n",
       "      <td>-0.016278</td>\n",
       "      <td>0.071778</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>-4.160142</td>\n",
       "      <td>-2.382114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1.129021</td>\n",
       "      <td>16.329800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.591499</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>-2.582771</td>\n",
       "      <td>0.013623</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-0.328521</td>\n",
       "      <td>0.019801</td>\n",
       "      <td>0.022991</td>\n",
       "      <td>-4.682147</td>\n",
       "      <td>-1.212850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.522359</td>\n",
       "      <td>17</td>\n",
       "      <td>0.020277</td>\n",
       "      <td>19.061896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.104598</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-3.145087</td>\n",
       "      <td>0.013695</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>0.014641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008245</td>\n",
       "      <td>-4.843486</td>\n",
       "      <td>-1.088557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>0.663349</td>\n",
       "      <td>17.663472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AD  DEPRESSION_SUB        IQ  NEUROTICISM  WORRY_SUB  INSOMNIA  \\\n",
       "0 -5.780160        0.002583 -2.917600     0.013433  -0.000821 -0.307129   \n",
       "1  9.133668        0.002060  0.369931     0.000064  -0.001469  0.438520   \n",
       "2  2.059180        0.006631 -4.261953     0.012193  -0.016278  0.071778   \n",
       "3  8.591499        0.004259 -2.582771     0.013623   0.000487 -0.328521   \n",
       "4  3.104598        0.000878 -3.145087     0.013695  -0.013129  0.014641   \n",
       "\n",
       "       PTSD   SNORING        CP  excl23andMe  ...  HAPPINESS  age  female  \\\n",
       "0  0.000000  0.063292 -2.156561    -0.248034  ...   0.002318  131       1   \n",
       "1  0.017525  0.021098 -3.683131    -1.858655  ...  -0.000128  126       0   \n",
       "2  0.010899  0.037388 -4.160142    -2.382114  ...  -0.001354  112       0   \n",
       "3  0.019801  0.022991 -4.682147    -1.212850  ...   0.001577  110       0   \n",
       "4  0.000000 -0.008245 -4.843486    -1.088557  ...  -0.000256  118       1   \n",
       "\n",
       "   race  high.educ  income   married  abcd_site       vol        BMI  \n",
       "0   1.0       13.0     8.0  1.000000          6 -1.050932  20.480539  \n",
       "1   1.0       19.0    10.0  1.000000         22  1.293196  18.234286  \n",
       "2   1.0       20.0    10.0  1.000000          7  1.129021  16.329800  \n",
       "3   5.0       21.0     6.0  1.522359         17  0.020277  19.061896  \n",
       "4   1.0       16.0     8.0  1.000000         17  0.663349  17.663472  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = my_data.iloc[:, 1:35]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.632147\n",
       "1    1.069812\n",
       "2    0.632147\n",
       "3    0.329044\n",
       "4   -0.680849\n",
       "Name: NIH_totcomp, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = my_data['NIH_totcomp']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_cv = KFold(n_splits = k_fold, shuffle=False, random_state = 123)\n",
    "outer_cv = KFold(n_splits = k_fold, shuffle=False, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Loop:  1\n",
      "    mean_test_score  std_test_score                                 params\n",
      "0          0.180390        0.024770   {'max_depth': 5, 'n_estimators': 10}\n",
      "1          0.186106        0.024487   {'max_depth': 5, 'n_estimators': 20}\n",
      "2          0.189756        0.022257   {'max_depth': 5, 'n_estimators': 30}\n",
      "3          0.191499        0.022479   {'max_depth': 5, 'n_estimators': 40}\n",
      "4          0.193095        0.024103   {'max_depth': 5, 'n_estimators': 50}\n",
      "5          0.193249        0.024272   {'max_depth': 5, 'n_estimators': 60}\n",
      "6          0.193110        0.024760   {'max_depth': 5, 'n_estimators': 70}\n",
      "7          0.192383        0.026563   {'max_depth': 5, 'n_estimators': 80}\n",
      "8          0.191108        0.025675   {'max_depth': 5, 'n_estimators': 90}\n",
      "9          0.192083        0.024919  {'max_depth': 5, 'n_estimators': 100}\n",
      "10         0.192662        0.024513  {'max_depth': 5, 'n_estimators': 110}\n",
      "11         0.193169        0.023744  {'max_depth': 5, 'n_estimators': 120}\n",
      "12         0.193689        0.023238  {'max_depth': 5, 'n_estimators': 130}\n",
      "13         0.194201        0.023359  {'max_depth': 5, 'n_estimators': 140}\n",
      "14         0.193741        0.024207  {'max_depth': 5, 'n_estimators': 150}\n",
      "15         0.193550        0.023575  {'max_depth': 5, 'n_estimators': 160}\n",
      "16         0.193273        0.023937  {'max_depth': 5, 'n_estimators': 170}\n",
      "17         0.192488        0.024394  {'max_depth': 5, 'n_estimators': 180}\n",
      "18         0.191642        0.024179  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train parameter:  {'max_depth': 5, 'n_estimators': 140}\n",
      "best train score:  0.19420124988771337\n",
      "\n",
      "\n",
      "test score:  0.13807689981295945\n",
      "----------------------------\n",
      "----------------------------\n",
      "Loop:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score                                 params\n",
      "0          0.169867        0.028466   {'max_depth': 5, 'n_estimators': 10}\n",
      "1          0.179002        0.029991   {'max_depth': 5, 'n_estimators': 20}\n",
      "2          0.176535        0.028647   {'max_depth': 5, 'n_estimators': 30}\n",
      "3          0.178810        0.029275   {'max_depth': 5, 'n_estimators': 40}\n",
      "4          0.177322        0.029503   {'max_depth': 5, 'n_estimators': 50}\n",
      "5          0.175886        0.028418   {'max_depth': 5, 'n_estimators': 60}\n",
      "6          0.175943        0.028610   {'max_depth': 5, 'n_estimators': 70}\n",
      "7          0.177041        0.028558   {'max_depth': 5, 'n_estimators': 80}\n",
      "8          0.177999        0.028912   {'max_depth': 5, 'n_estimators': 90}\n",
      "9          0.177966        0.028111  {'max_depth': 5, 'n_estimators': 100}\n",
      "10         0.178165        0.028808  {'max_depth': 5, 'n_estimators': 110}\n",
      "11         0.178003        0.028330  {'max_depth': 5, 'n_estimators': 120}\n",
      "12         0.176960        0.028882  {'max_depth': 5, 'n_estimators': 130}\n",
      "13         0.178056        0.028946  {'max_depth': 5, 'n_estimators': 140}\n",
      "14         0.177899        0.029618  {'max_depth': 5, 'n_estimators': 150}\n",
      "15         0.177520        0.029895  {'max_depth': 5, 'n_estimators': 160}\n",
      "16         0.177940        0.030531  {'max_depth': 5, 'n_estimators': 170}\n",
      "17         0.177669        0.030125  {'max_depth': 5, 'n_estimators': 180}\n",
      "18         0.178307        0.030457  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train parameter:  {'max_depth': 5, 'n_estimators': 20}\n",
      "best train score:  0.17900163518610437\n",
      "\n",
      "\n",
      "test score:  0.17778680180143758\n",
      "----------------------------\n",
      "----------------------------\n",
      "Loop:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score                                 params\n",
      "0          0.172857        0.027181   {'max_depth': 5, 'n_estimators': 10}\n",
      "1          0.181504        0.027357   {'max_depth': 5, 'n_estimators': 20}\n",
      "2          0.183284        0.024636   {'max_depth': 5, 'n_estimators': 30}\n",
      "3          0.183849        0.026357   {'max_depth': 5, 'n_estimators': 40}\n",
      "4          0.184021        0.025726   {'max_depth': 5, 'n_estimators': 50}\n",
      "5          0.181860        0.026373   {'max_depth': 5, 'n_estimators': 60}\n",
      "6          0.182844        0.025329   {'max_depth': 5, 'n_estimators': 70}\n",
      "7          0.182017        0.025605   {'max_depth': 5, 'n_estimators': 80}\n",
      "8          0.182295        0.026950   {'max_depth': 5, 'n_estimators': 90}\n",
      "9          0.183023        0.025574  {'max_depth': 5, 'n_estimators': 100}\n",
      "10         0.182165        0.025924  {'max_depth': 5, 'n_estimators': 110}\n",
      "11         0.182408        0.025914  {'max_depth': 5, 'n_estimators': 120}\n",
      "12         0.182675        0.026078  {'max_depth': 5, 'n_estimators': 130}\n",
      "13         0.183455        0.026227  {'max_depth': 5, 'n_estimators': 140}\n",
      "14         0.183533        0.027567  {'max_depth': 5, 'n_estimators': 150}\n",
      "15         0.183563        0.027242  {'max_depth': 5, 'n_estimators': 160}\n",
      "16         0.183987        0.028483  {'max_depth': 5, 'n_estimators': 170}\n",
      "17         0.185158        0.027746  {'max_depth': 5, 'n_estimators': 180}\n",
      "18         0.184839        0.027095  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train parameter:  {'max_depth': 5, 'n_estimators': 180}\n",
      "best train score:  0.18515760299409115\n",
      "\n",
      "\n",
      "test score:  0.16556918862944825\n",
      "----------------------------\n",
      "----------------------------\n",
      "Loop:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score                                 params\n",
      "0          0.149948        0.019624   {'max_depth': 5, 'n_estimators': 10}\n",
      "1          0.159039        0.016069   {'max_depth': 5, 'n_estimators': 20}\n",
      "2          0.160959        0.015962   {'max_depth': 5, 'n_estimators': 30}\n",
      "3          0.161708        0.015907   {'max_depth': 5, 'n_estimators': 40}\n",
      "4          0.163413        0.016797   {'max_depth': 5, 'n_estimators': 50}\n",
      "5          0.164445        0.016873   {'max_depth': 5, 'n_estimators': 60}\n",
      "6          0.165070        0.018124   {'max_depth': 5, 'n_estimators': 70}\n",
      "7          0.166247        0.017477   {'max_depth': 5, 'n_estimators': 80}\n",
      "8          0.165466        0.015442   {'max_depth': 5, 'n_estimators': 90}\n",
      "9          0.166327        0.017551  {'max_depth': 5, 'n_estimators': 100}\n",
      "10         0.165973        0.017384  {'max_depth': 5, 'n_estimators': 110}\n",
      "11         0.165420        0.018553  {'max_depth': 5, 'n_estimators': 120}\n",
      "12         0.165767        0.019243  {'max_depth': 5, 'n_estimators': 130}\n",
      "13         0.166477        0.019749  {'max_depth': 5, 'n_estimators': 140}\n",
      "14         0.166501        0.018595  {'max_depth': 5, 'n_estimators': 150}\n",
      "15         0.166499        0.019329  {'max_depth': 5, 'n_estimators': 160}\n",
      "16         0.166769        0.019284  {'max_depth': 5, 'n_estimators': 170}\n",
      "17         0.167031        0.019507  {'max_depth': 5, 'n_estimators': 180}\n",
      "18         0.167269        0.018472  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train parameter:  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train score:  0.16726856929528872\n",
      "\n",
      "\n",
      "test score:  0.22719481228245697\n",
      "----------------------------\n",
      "----------------------------\n",
      "Loop:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_test_score  std_test_score                                 params\n",
      "0          0.164739        0.030450   {'max_depth': 5, 'n_estimators': 10}\n",
      "1          0.172673        0.031825   {'max_depth': 5, 'n_estimators': 20}\n",
      "2          0.173896        0.032397   {'max_depth': 5, 'n_estimators': 30}\n",
      "3          0.175396        0.031724   {'max_depth': 5, 'n_estimators': 40}\n",
      "4          0.176944        0.031211   {'max_depth': 5, 'n_estimators': 50}\n",
      "5          0.176524        0.029837   {'max_depth': 5, 'n_estimators': 60}\n",
      "6          0.177545        0.028950   {'max_depth': 5, 'n_estimators': 70}\n",
      "7          0.177957        0.027806   {'max_depth': 5, 'n_estimators': 80}\n",
      "8          0.178435        0.029228   {'max_depth': 5, 'n_estimators': 90}\n",
      "9          0.177569        0.029051  {'max_depth': 5, 'n_estimators': 100}\n",
      "10         0.178235        0.029743  {'max_depth': 5, 'n_estimators': 110}\n",
      "11         0.178059        0.029480  {'max_depth': 5, 'n_estimators': 120}\n",
      "12         0.178250        0.029587  {'max_depth': 5, 'n_estimators': 130}\n",
      "13         0.178050        0.028010  {'max_depth': 5, 'n_estimators': 140}\n",
      "14         0.178312        0.027979  {'max_depth': 5, 'n_estimators': 150}\n",
      "15         0.178431        0.028053  {'max_depth': 5, 'n_estimators': 160}\n",
      "16         0.178696        0.028769  {'max_depth': 5, 'n_estimators': 170}\n",
      "17         0.178664        0.030262  {'max_depth': 5, 'n_estimators': 180}\n",
      "18         0.178232        0.030485  {'max_depth': 5, 'n_estimators': 190}\n",
      "best train parameter:  {'max_depth': 5, 'n_estimators': 170}\n",
      "best train score:  0.1786962004729495\n",
      "\n",
      "\n",
      "test score:  0.19928802384664324\n",
      "----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/ubuntu/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "outerloop = 0\n",
    "\n",
    "for train_index, test_index in outer_cv.split(X, y):\n",
    "    outerloop += 1\n",
    "    print('----------------------------')\n",
    "    print('Loop: ', outerloop)\n",
    "    \n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    params = {'n_estimators': np.arange(10, 200, 10),\n",
    "              'max_depth': [5]}\n",
    "    \n",
    "    rf = RandomForestRegressor()\n",
    "    rf_grid = GridSearchCV(estimator = rf, param_grid = params, cv = inner_cv, scoring='r2', n_jobs=-1, return_train_score=True)\n",
    "    \n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    y_pred_test = rf_grid.predict(X_test)\n",
    "    #y_pred_train = rf_grid.predict(X_train)\n",
    "    \n",
    "    result = pd.DataFrame(rf_grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]\n",
    "    print(result)\n",
    "    print('best train parameter: ', rf_grid.best_params_)\n",
    "    print('best train score: ', rf_grid.best_score_)\n",
    "    print('\\n')\n",
    "    print('test score: ', r2_score(y_test, y_pred_test))\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### score is R2 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python3)",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
